# ðŸ¤– Machine Learning Backend Documentation

> **Comprehensive Guide to the Student Performance Prediction ML Pipeline**

## ðŸ“‹ Overview

The ML backend implements a complete machine learning pipeline for predicting student academic performance using Linear Regression. The system processes student data through multiple stages: data loading, exploration, cleaning, feature engineering, model training, evaluation, and visualization.

## ðŸ—ï¸ Architecture

```
Data Input â†’ Data Exploration â†’ Data Cleaning â†’ Feature Engineering â†’ Model Training â†’ Evaluation â†’ Visualization
```

## ðŸ“Š Dataset Analysis

### **StudentPerformanceFactors.csv**
- **Records**: 6,607 students
- **Features**: 20 variables (numerical + categorical)
- **Target**: Exam_Score (0-100)

### **Feature Categories**

#### Academic Factors
- `Hours_Studied`: Study time per day (1-50 hours)
- `Attendance`: Class attendance percentage (60-100%)
- `Previous_Scores`: Previous exam performance (0-100)
- `Tutoring_Sessions`: Number of tutoring sessions (0-10)

#### Personal Factors
- `Sleep_Hours`: Daily sleep duration (4-12 hours)
- `Physical_Activity`: Activity level (0-6 scale)
- `Motivation_Level`: Self-reported motivation (Low/Medium/High)
- `Learning_Disabilities`: Presence of learning challenges (Yes/No)

#### Environmental Factors
- `Parental_Involvement`: Parent engagement level (Low/Medium/High)
- `Access_to_Resources`: Resource availability (Low/Medium/High)
- `Teacher_Quality`: Perceived teacher effectiveness (Low/Medium/High)
- `School_Type`: Institution type (Public/Private)

#### Social Factors
- `Peer_Influence`: Peer impact on learning (Positive/Neutral/Negative)
- `Extracurricular_Activities`: Participation in activities (Yes/No)

## ðŸ”§ Data Processing Pipeline

### 1. Data Loading & Exploration
```python
def load_data(self):
    """Load CSV dataset and display basic information"""
    self.data = pd.read_csv(self.data_path)
    print(f"Dataset shape: {self.data.shape}")
    print(f"Columns: {list(self.data.columns)}")
    print(f"Data types: {self.data.dtypes}")
    print(f"Missing values: {self.data.isnull().sum()}")
```

### 2. Data Cleaning
```python
def clean_data(self):
    """Handle missing values and encode categorical variables"""
    # Fill missing values
    categorical_cols = self.data.select_dtypes(include=['object']).columns
    numerical_cols = self.data.select_dtypes(include=['int64', 'float64']).columns
    
    # Mode for categorical, median for numerical
    for col in categorical_cols:
        self.data[col].fillna(self.data[col].mode()[0], inplace=True)
    
    for col in numerical_cols:
        self.data[col].fillna(self.data[col].median(), inplace=True)
    
    # Encode categorical variables
    self.label_encoders = {}
    for col in categorical_cols:
        le = LabelEncoder()
        self.data[col] = le.fit_transform(self.data[col])
        self.label_encoders[col] = le
```

### 3. Feature Engineering
```python
def prepare_features(self):
    """Select features and prepare for modeling"""
    # Select all features except target
    feature_cols = [col for col in self.data.columns if col != 'Exam_Score']
    X = self.data[feature_cols]
    y = self.data['Exam_Score']
    
    # Train-test split (80/20)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # Scale features
    self.scaler = StandardScaler()
    X_train_scaled = self.scaler.fit_transform(X_train)
    X_test_scaled = self.scaler.transform(X_test)
    
    return X_train_scaled, X_test_scaled, y_train, y_test
```

## ðŸ§  Model Implementation

### Linear Regression Algorithm
```python
def train_model(self):
    """Train Linear Regression model"""
    # Initialize model
    self.model = LinearRegression()
    
    # Train on scaled features
    self.model.fit(self.X_train_scaled, self.y_train)
    
    # Make predictions
    y_train_pred = self.model.predict(self.X_train_scaled)
    y_test_pred = self.model.predict(self.X_test_scaled)
    
    # Store predictions
    self.train_predictions = y_train_pred
    self.test_predictions = y_test_pred
    
    # Display coefficients
    feature_names = [col for col in self.data.columns if col != 'Exam_Score']
    coefficients = pd.DataFrame({
        'Feature': feature_names,
        'Coefficient': self.model.coef_
    }).sort_values('Coefficient', key=abs, ascending=False)
    
    print("Feature Importance:")
    print(coefficients)
```

### Model Coefficients Interpretation
- **Positive coefficients**: Feature increases exam score
- **Negative coefficients**: Feature decreases exam score
- **Magnitude**: Relative importance of the feature

## ðŸ“ˆ Model Evaluation

### Performance Metrics
```python
def evaluate_model(self):
    """Calculate and display model performance metrics"""
    # Training set metrics
    train_mse = mean_squared_error(self.y_train, self.train_predictions)
    train_rmse = np.sqrt(train_mse)
    train_mae = mean_absolute_error(self.y_train, self.train_predictions)
    train_r2 = r2_score(self.y_train, self.train_predictions)
    
    # Testing set metrics
    test_mse = mean_squared_error(self.y_test, self.test_predictions)
    test_rmse = np.sqrt(test_mse)
    test_mae = mean_absolute_error(self.y_test, self.test_predictions)
    test_r2 = r2_score(self.y_test, self.test_predictions)
    
    # Store metrics
    self.metrics = {
        'train': {'mse': train_mse, 'rmse': train_rmse, 'mae': train_mae, 'r2': train_r2},
        'test': {'mse': test_mse, 'rmse': test_rmse, 'mae': test_mae, 'r2': test_r2}
    }
```

### Metric Interpretations
- **RÂ² Score**: 0.64-0.69 (64-69% variance explained)
- **RMSE**: 5-7 points (typical prediction error)
- **MAE**: 4-6 points (average absolute error)
- **MSE**: Mean squared error (higher penalty for large errors)

## ðŸŽ¨ Visualization System

### Generated Charts
1. **Student Performance Analysis** (`student_performance_analysis.png`)
   - Exam score distribution
   - Study hours vs. score scatter plots
   - Attendance correlation
   - Sleep hours impact
   - Feature correlation heatmap

2. **Model Performance Analysis** (`model_performance_analysis.png`)
   - Actual vs. predicted plots
   - Residuals analysis
   - Performance metrics comparison

3. **Feature Importance** (`feature_importance.png`)
   - Coefficient magnitude visualization
   - Feature ranking by importance

## ðŸ”® Prediction Interface

### Making Predictions
```python
def make_prediction(self, student_features):
    """Predict exam score for new student"""
    # Preprocess features
    processed_features = self._preprocess_features(student_features)
    
    # Scale features
    scaled_features = self.scaler.transform([processed_features])
    
    # Make prediction
    predicted_score = self.model.predict(scaled_features)[0]
    
    return round(predicted_score, 2)
```

### Input Format
```python
student_features = {
    'Hours_Studied': 25,
    'Attendance': 90,
    'Parental_Involvement': 'High',
    'Access_to_Resources': 'High',
    'Extracurricular_Activities': 'Yes',
    'Sleep_Hours': 8,
    'Previous_Scores': 85,
    'Motivation_Level': 'High',
    'Internet_Access': 'Yes',
    'Tutoring_Sessions': 2,
    'Family_Income': 'Medium',
    'Teacher_Quality': 'High',
    'School_Type': 'Private',
    'Peer_Influence': 'Positive',
    'Physical_Activity': 4,
    'Learning_Disabilities': 'No',
    'Parental_Education_Level': 'College',
    'Distance_from_Home': 'Near',
    'Gender': 'Female'
}
```

## ðŸš€ Usage Examples

### Running Complete Analysis
```bash
cd backend
source student_prediction_env/bin/activate
python notebooks/student_score_prediction.py
```

### Jupyter Notebook
```bash
cd backend
source student_prediction_env/bin/activate
jupyter notebook
# Open student_score_prediction.ipynb
```

### Custom Predictions
```python
from notebooks.student_score_prediction import StudentScorePredictor

# Initialize predictor
predictor = StudentScorePredictor('data/StudentPerformanceFactors.csv')

# Run analysis
predictor.run_complete_analysis()

# Make custom prediction
score = predictor.make_prediction(student_features)
print(f"Predicted Score: {score}")
```

## ðŸ“Š Performance Insights

### Key Findings
1. **Study Hours**: Strongest positive correlation with exam scores
2. **Attendance**: Critical factor for academic success
3. **Previous Performance**: Good predictor of future results
4. **Parental Involvement**: Significant positive impact
5. **Teacher Quality**: Important environmental factor

### Model Limitations
- Linear relationships only
- Assumes feature independence
- May not capture complex interactions
- Requires sufficient training data

## ðŸ”§ Customization

### Adding New Features
1. Update dataset with new columns
2. Modify feature selection in `prepare_features()`
3. Retrain model with new features
4. Update prediction interface

### Model Improvements
- Try different algorithms (Random Forest, XGBoost)
- Implement feature selection methods
- Add cross-validation
- Use hyperparameter tuning

## ðŸ“š Dependencies

```txt
pandas>=1.5.0      # Data manipulation
numpy>=1.21.0      # Numerical computing
matplotlib>=3.5.0  # Basic plotting
seaborn>=0.11.0    # Statistical visualization
scikit-learn>=1.1.0 # Machine learning
jupyter>=1.0.0     # Interactive development
```

---

*This documentation provides comprehensive coverage of the ML backend implementation. For specific questions or customizations, refer to the code comments or create an issue.* 